#!/usr/bin/env python3
"""
COMPREHENSIVE TOURNAMENT DATA IMPORT
Importiert ALLE Spieldaten fÃ¼r alle gefundenen Turniere in die Datenbank

Nutzt die Ergebnisse von complete_tournament_discovery.py um zu wissen,
welche Turniere verfÃ¼gbar sind, und importiert dann ALLE Spiel-Daten
(nicht nur 5 Test-Games).
"""

import json
import time
import os
import sys
from pathlib import Path
from datetime import datetime
from collections import defaultdict

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from core.leaguepedia_loader import LeaguepediaLoader
from core.database import DatabaseManager
from core.team_resolver import TeamResolver

def aggregate_games_to_matches(games):
    """
    Aggregate individual games into matches

    Groups games by (Team1, Team2, Date, Tab) to form matches,
    then calculates match scores (wins per team)

    Args:
        games: List of game dictionaries from ScoreboardGames

    Returns:
        List of match dictionaries with aggregated scores
    """
    # Group games by match identifier
    matches_dict = defaultdict(list)

    for game in games:
        team1 = game.get('Team1', '').strip()
        team2 = game.get('Team2', '').strip()
        date = game.get('DateTime_UTC', '')
        tab = game.get('Tab', '')

        if not team1 or not team2:
            continue

        # Extract date only (ignore time)
        game_date = date.split()[0] if date else ''

        # Create match key: teams + date + tab
        # Tab helps distinguish multiple matches on same day
        match_key = (team1, team2, game_date, tab)
        matches_dict[match_key].append(game)

    # Aggregate each match
    matches = []
    for (team1, team2, game_date, tab), match_games in matches_dict.items():
        # Count wins for each team
        team1_score = sum(1 for g in match_games if g.get('Winner') == '1')
        team2_score = sum(1 for g in match_games if g.get('Winner') == '2')

        # Use data from first game for shared fields
        first_game = match_games[0]

        # Collect all GameIds for this match (for player data lookup)
        game_ids = [g.get('GameId', '') for g in match_games if g.get('GameId')]

        match = {
            'team1': team1,
            'team2': team2,
            'team1_score': team1_score,
            'team2_score': team2_score,
            'date': first_game.get('DateTime_UTC', ''),
            'tournament': first_game.get('Tournament', ''),
            'league': first_game.get('League', ''),
            'patch': first_game.get('Patch', ''),
            'tab': tab,
            'overview_page': first_game.get('OverviewPage', ''),
            'num_games': len(match_games),
            'game_ids': game_ids,  # For player data lookup
            'external_id': f"{first_game.get('OverviewPage', '')}_{tab}_{game_date}_{team1}_{team2}"
        }

        matches.append(match)

    return matches

def import_tournament(loader, db, team_resolver, name, url, stats, include_players=True):
    """
    Import all games for a single tournament

    Args:
        loader: LeaguepediaLoader instance
        db: DatabaseManager instance
        team_resolver: TeamResolver instance
        name: Tournament name
        url: Tournament URL
        stats: Statistics dictionary
        include_players: Whether to fetch player data (default: True, only fetches Link and Role)
    """
    print(f"\nImporting: {name}")
    print(f"  URL: {url}")

    try:
        # Query ALL games (not just 5)
        time.sleep(2)  # Rate limit delay
        games = loader._query_cargo(
            tables="ScoreboardGames",
            fields="Team1,Team2,Winner,DateTime_UTC,GameId,OverviewPage,Team1Score,Team2Score,Patch,Tournament,League,Tab",
            where=f"OverviewPage='{url}'",
            limit=500,  # Get up to 500 games per tournament
            order_by="DateTime_UTC ASC"
        )

        if not games or len(games) == 0:
            print(f"  âš ï¸  No games found (skipping)")
            stats["skipped"] += 1
            return False

        print(f"  ğŸ“Š Found {len(games)} games")

        # Query player data if requested (only Link and Role to keep it lightweight)
        players_by_game = {}
        if include_players:
            time.sleep(2)  # Rate limit delay
            players = loader._query_cargo(
                tables="ScoreboardPlayers",
                fields="GameId,Link,Role,Team",
                where=f"OverviewPage='{url}'",
                limit=500,  # 500 per request
                order_by="DateTime_UTC ASC"
            )

            # Group players by GameId for easy lookup
            for player in players:
                game_id = player.get('GameId', '')
                if game_id not in players_by_game:
                    players_by_game[game_id] = []
                players_by_game[game_id].append(player)

            print(f"  ğŸ‘¤ Found {len(players)} player records")

        # Aggregate games into matches
        matches = aggregate_games_to_matches(games)
        print(f"  ğŸ“Š Aggregated into {len(matches)} matches")

        # Import each match into database
        imported = 0
        duplicates = 0
        players_imported = 0

        for match in matches:
            # Resolve team names using TeamResolver
            team1_resolved = team_resolver.resolve(match['team1'], match['date'])
            team2_resolved = team_resolver.resolve(match['team2'], match['date'])

            # Parse date
            try:
                match_date = datetime.strptime(match['date'], '%Y-%m-%d %H:%M:%S')
            except:
                # Fallback for different date formats
                try:
                    match_date = datetime.strptime(match['date'].split()[0], '%Y-%m-%d')
                except:
                    print(f"    âš ï¸  Could not parse date: {match['date']}")
                    continue

            # Insert match into database
            match_id = db.insert_match(
                team1_name=team1_resolved,
                team2_name=team2_resolved,
                team1_score=match['team1_score'],
                team2_score=match['team2_score'],
                date=match_date,
                tournament_name=match['tournament'],
                stage=match['tab'],
                patch=match['patch'],
                external_id=match['external_id'],
                source='leaguepedia',
                region=None,  # Could be extracted from tournament name
                tournament_type=None  # Could be inferred from tournament name
            )

            if match_id:
                imported += 1

                # Insert player data if available
                if include_players and players_by_game:
                    # Collect all players from all games in this match
                    match_players = []
                    for game_id in match.get('game_ids', []):
                        if game_id in players_by_game:
                            match_players.extend(players_by_game[game_id])

                    # Insert each unique player (deduplicate by name+role)
                    unique_players = {}
                    for player in match_players:
                        player_name = player.get('Link', '').strip()
                        role = player.get('Role', '').strip()
                        team = player.get('Team', '').strip()

                        if not player_name:
                            continue

                        # Resolve team name
                        team_resolved = team_resolver.resolve(team, match['date'])

                        # Use (name, role) as unique key to avoid duplicates
                        key = (player_name, role)
                        if key not in unique_players:
                            unique_players[key] = (player_name, role, team_resolved)

                    # Insert into database
                    for player_name, role, team_name in unique_players.values():
                        result = db.insert_match_player(
                            match_id=match_id,
                            player_name=player_name,
                            team_name=team_name,
                            role=role
                        )
                        if result:
                            players_imported += 1

            else:
                duplicates += 1

        if include_players and players_imported > 0:
            print(f"  âœ… Imported {imported} matches, {players_imported} player records ({duplicates} duplicates skipped)")
        else:
            print(f"  âœ… Imported {imported} matches ({duplicates} duplicates skipped)")

        stats["imported"] += imported
        stats["duplicates"] += duplicates
        stats["players_imported"] = stats.get("players_imported", 0) + players_imported
        stats["tournaments_imported"] += 1
        return True

    except Exception as e:
        print(f"  âŒ Error: {str(e)}")
        stats["errors"] += 1
        import traceback
        traceback.print_exc()
        return False

def main():
    print("="*80)
    print("COMPREHENSIVE TOURNAMENT DATA IMPORT")
    print("="*80)
    print("Importiert ALLE Spiel-Daten in die Datenbank\n")

    # Load discovery results
    results_file = Path(__file__).parent / "complete_tournament_discovery_results.json"

    if not results_file.exists():
        print("âŒ ERROR: complete_tournament_discovery_results.json not found!")
        print("   Run complete_tournament_discovery.py first to discover available tournaments.")
        sys.exit(1)

    with open(results_file, 'r', encoding='utf-8') as f:
        discovery_results = json.load(f)

    # Filter to only found tournaments
    found_tournaments = {
        name: data for name, data in discovery_results.items()
        if data.get("status") == "found"
    }

    print(f"Found {len(found_tournaments)} tournaments to import\n")

    if len(found_tournaments) == 0:
        print("âŒ No tournaments found to import!")
        sys.exit(1)

    # Initialize loader, database, and team resolver
    loader = LeaguepediaLoader()
    db = DatabaseManager()
    team_resolver = TeamResolver(loader=loader, db=db)

    stats = {
        "imported": 0,
        "duplicates": 0,
        "players_imported": 0,
        "tournaments_imported": 0,
        "skipped": 0,
        "errors": 0
    }

    # Import each tournament
    print("="*80)
    print("STARTING IMPORT")
    print("="*80)

    for i, (name, data) in enumerate(found_tournaments.items(), 1):
        print(f"\n[{i}/{len(found_tournaments)}] ", end="")
        url = data["url"]
        import_tournament(loader, db, team_resolver, name, url, stats)

    # Summary
    print("\n" + "="*80)
    print("IMPORT COMPLETE")
    print("="*80)
    print(f"\nâœ… Tournaments imported:   {stats['tournaments_imported']:4d}")
    print(f"ğŸ“Š Total matches imported: {stats['imported']:4d}")
    print(f"ğŸ‘¤ Player records imported: {stats['players_imported']:4d}")
    print(f"ğŸ”„ Duplicates skipped:     {stats['duplicates']:4d}")
    print(f"âš ï¸  Skipped:               {stats['skipped']:4d}")
    print(f"âŒ Errors:                {stats['errors']:4d}")

    # Save unknown teams for manual review
    unknown_teams = team_resolver.get_unknown_teams()
    if unknown_teams:
        print(f"\nâš ï¸  Found {len(unknown_teams)} unknown team names")
        unknown_file = Path(__file__).parent / "unknown_teams.txt"
        team_resolver.save_unknown_teams(str(unknown_file))

    # Get database statistics
    db_stats = db.get_stats()
    print(f"\nğŸ“Š Database Statistics:")
    print(f"  Total matches: {db_stats['total_matches']}")
    print(f"  Total teams: {db_stats['total_teams']}")
    print(f"  Total tournaments: {db_stats['total_tournaments']}")
    if db_stats['date_range'][0]:
        print(f"  Date range: {db_stats['date_range'][0]} to {db_stats['date_range'][1]}")

    # Save import log
    import_log = {
        "timestamp": datetime.now().isoformat(),
        "stats": stats,
        "db_stats": db_stats,
        "tournaments": list(found_tournaments.keys()),
        "unknown_teams": unknown_teams
    }

    log_file = Path(__file__).parent / "import_log.json"
    with open(log_file, "w", encoding="utf-8") as f:
        json.dump(import_log, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“„ Import log saved to: {log_file}")

if __name__ == "__main__":
    main()
